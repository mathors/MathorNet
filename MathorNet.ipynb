{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MathorNet.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4DcQnfoMXk4",
        "colab_type": "code",
        "outputId": "c3dc5899-da6a-4bd0-d677-0f156bcc7a3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "import time\n",
        "import os\n",
        "print(\"PyTorch Version: \",torch.__version__)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PyTorch Version:  1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGNPyj3OMkWm",
        "colab_type": "text"
      },
      "source": [
        "## 加载数据集"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68ANNKN0Mc1P",
        "colab_type": "code",
        "outputId": "c03be117-be3f-470c-e888-149005fb1702",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# transform 接受一个图像返回变换后的图像的函数，相当于图像先预处理下\n",
        "# 常用的操作如 ToTensor, RandomCrop，Normalize等. \n",
        "# 他们可以通过transforms.Compose被组合在一起 \n",
        "transform = transforms.Compose([\n",
        "     transforms.RandomHorizontalFlip(), # 随机水平翻转\n",
        "     transforms.RandomGrayscale(), # 图像随机转换为灰度\n",
        "     transforms.ToTensor(), # # .ToTensor()将shape为(H, W, C)的nump.ndarray或img转为shape为(C, H, W)的tensor\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "     #.Normalize作用就是.ToTensor将输入归一化到(0,1)后，再使用公式”(x-mean)/std”，将每个元素分布到(-1,1)\n",
        "\n",
        "transform1 = transforms.Compose([\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, # 如果true，从training.pt创建数据集\n",
        "                                        download=True, # 如果ture，从网上自动下载\n",
        "                                        transform=transform)\n",
        "# torch.utils.data.DataLoader在训练模型时使用到此函数，用来把训练数据分成多个batch，\n",
        "# 此函数每次抛出一个batch数据，直至把所有的数据都抛出，train_loader返回一个数据迭代器\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=100,\n",
        "                                          shuffle=True, # 随机打乱数据\n",
        "                                          ) # kwargs是上面gpu的设置\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, # 如果False，从test.pt创建数据集\n",
        "                                       download=True, transform=transform1)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=50,\n",
        "                                         shuffle=False,\n",
        "                                         )"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fppjEkm_RbbV",
        "colab_type": "code",
        "outputId": "73cde366-dddf-4447-feef-e114fb50fabe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "trainloader.dataset[0][0].shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 32, 32])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BMEr_bHRgAM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-6RlLsxSD79",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net,self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3,64,3,padding=1)\n",
        "        self.conv2 = nn.Conv2d(64,64,3,padding=1)\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu1 = nn.ReLU()\n",
        "\n",
        "        self.conv3 = nn.Conv2d(64,128,3,padding=1)\n",
        "        self.conv4 = nn.Conv2d(128, 128, 3,padding=1)\n",
        "        self.pool2 = nn.MaxPool2d(2, 2, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(128)\n",
        "        self.relu2 = nn.ReLU()\n",
        "\n",
        "        self.conv5 = nn.Conv2d(128,128, 3,padding=1)\n",
        "        self.conv6 = nn.Conv2d(128, 128, 3,padding=1)\n",
        "        self.conv7 = nn.Conv2d(128, 128, 1,padding=1)\n",
        "        self.pool3 = nn.MaxPool2d(2, 2, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.relu3 = nn.ReLU()\n",
        "\n",
        "        self.conv8 = nn.Conv2d(128, 256, 3,padding=1)\n",
        "        self.conv9 = nn.Conv2d(256, 256, 3, padding=1)\n",
        "        self.conv10 = nn.Conv2d(256, 256, 1, padding=1)\n",
        "        self.pool4 = nn.MaxPool2d(2, 2, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(256)\n",
        "        self.relu4 = nn.ReLU()\n",
        "\n",
        "        self.conv11 = nn.Conv2d(256, 512, 3, padding=1)\n",
        "        self.conv12 = nn.Conv2d(512, 512, 3, padding=1)\n",
        "        self.conv13 = nn.Conv2d(512, 512, 1, padding=1)\n",
        "        self.pool5 = nn.MaxPool2d(2, 2, padding=1)\n",
        "        self.bn5 = nn.BatchNorm2d(512)\n",
        "        self.relu5 = nn.ReLU()\n",
        "\n",
        "        self.fc14 = nn.Linear(512*4*4,1024)\n",
        "        self.drop1 = nn.Dropout2d()\n",
        "        self.fc15 = nn.Linear(1024,1024)\n",
        "        self.drop2 = nn.Dropout2d()\n",
        "        self.fc16 = nn.Linear(1024,10)\n",
        "\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.pool1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu1(x)\n",
        "\n",
        "\n",
        "        x = self.conv3(x)\n",
        "        x = self.conv4(x)\n",
        "        x = self.pool2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu2(x)\n",
        "\n",
        "        x = self.conv5(x)\n",
        "        x = self.conv6(x)\n",
        "        x = self.conv7(x)\n",
        "        x = self.pool3(x)\n",
        "        x = self.bn3(x)\n",
        "        x = self.relu3(x)\n",
        "\n",
        "        x = self.conv8(x)\n",
        "        x = self.conv9(x)\n",
        "        x = self.conv10(x)\n",
        "        x = self.pool4(x)\n",
        "        x = self.bn4(x)\n",
        "        x = self.relu4(x)\n",
        "\n",
        "        x = self.conv11(x)\n",
        "        x = self.conv12(x)\n",
        "        x = self.conv13(x)\n",
        "        x = self.pool5(x)\n",
        "        x = self.bn5(x)\n",
        "        x = self.relu5(x)\n",
        "        # print(\" x shape \",x.size())\n",
        "        x = x.view(-1,512*4*4)\n",
        "        x = F.relu(self.fc14(x))\n",
        "        x = self.drop1(x)\n",
        "        x = F.relu(self.fc15(x))\n",
        "        x = self.drop2(x)\n",
        "        x = self.fc16(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def train_sgd(self,device):\n",
        "        optimizer = optim.Adam(self.parameters(), lr=0.0001)\n",
        "\n",
        "        path = 'weights.tar'\n",
        "        initepoch = 0\n",
        "\n",
        "        if os.path.exists(path) is not True:\n",
        "            loss = nn.CrossEntropyLoss()\n",
        "            # optimizer = optim.SGD(self.parameters(),lr=0.01)\n",
        "\n",
        "        else:\n",
        "            checkpoint = torch.load(path)\n",
        "            self.load_state_dict(checkpoint['model_state_dict'])\n",
        "            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "            initepoch = checkpoint['epoch']\n",
        "            loss = checkpoint['loss']\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        for epoch in range(initepoch,100):  # loop over the dataset multiple times\n",
        "            timestart = time.time()\n",
        "\n",
        "            running_loss = 0.0\n",
        "            total = 0\n",
        "            correct = 0\n",
        "            for i, data in enumerate(trainloader, 0):\n",
        "                # get the inputs\n",
        "                inputs, labels = data\n",
        "                inputs, labels = inputs.to(device),labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward + backward + optimize\n",
        "                outputs = self(inputs)\n",
        "                l = loss(outputs, labels)\n",
        "                l.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                # print statistics\n",
        "                running_loss += l.item()\n",
        "                # print(\"i \",i)\n",
        "                if i % 500 == 499:  # print every 500 mini-batches\n",
        "                    print('[%d, %5d] loss: %.4f' %\n",
        "                          (epoch, i, running_loss / 500))\n",
        "                    running_loss = 0.0\n",
        "                    _, predicted = torch.max(outputs.data, 1)\n",
        "                    total += labels.size(0)\n",
        "                    correct += (predicted == labels).sum().item()\n",
        "                    print('Accuracy of the network on the %d tran images: %.3f %%' % (total,\n",
        "                            100.0 * correct / total))\n",
        "                    total = 0\n",
        "                    correct = 0\n",
        "                    torch.save({'epoch':epoch,\n",
        "                                'model_state_dict':net.state_dict(),\n",
        "                                'optimizer_state_dict':optimizer.state_dict(),\n",
        "                                'loss':loss\n",
        "                                },path)\n",
        "\n",
        "            print('epoch %d cost %3f sec' %(epoch,time.time()-timestart))\n",
        "\n",
        "        print('Finished Training')\n",
        "\n",
        "    def test(self,device):\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for data in testloader:\n",
        "                images, labels = data\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = self(images)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        print('Accuracy of the network on the 10000 test images: %.3f %%' % (\n",
        "                100.0 * correct / total))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0C1K2TndVJei",
        "colab_type": "code",
        "outputId": "66eb6ecc-0d53-4332-f230-0ffb42d362a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5090
        }
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "net = Net()\n",
        "net = net.to(device)\n",
        "net.train_sgd(device)\n",
        "net.test(device)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0,   499] loss: 1.4200\n",
            "Accuracy of the network on the 100 tran images: 57.000 %\n",
            "epoch 0 cost 39.332747 sec\n",
            "[1,   499] loss: 0.9389\n",
            "Accuracy of the network on the 100 tran images: 74.000 %\n",
            "epoch 1 cost 38.856091 sec\n",
            "[2,   499] loss: 0.7670\n",
            "Accuracy of the network on the 100 tran images: 75.000 %\n",
            "epoch 2 cost 38.829908 sec\n",
            "[3,   499] loss: 0.6667\n",
            "Accuracy of the network on the 100 tran images: 69.000 %\n",
            "epoch 3 cost 38.978296 sec\n",
            "[4,   499] loss: 0.5888\n",
            "Accuracy of the network on the 100 tran images: 86.000 %\n",
            "epoch 4 cost 38.865795 sec\n",
            "[5,   499] loss: 0.5338\n",
            "Accuracy of the network on the 100 tran images: 81.000 %\n",
            "epoch 5 cost 39.045928 sec\n",
            "[6,   499] loss: 0.4889\n",
            "Accuracy of the network on the 100 tran images: 82.000 %\n",
            "epoch 6 cost 39.014673 sec\n",
            "[7,   499] loss: 0.4449\n",
            "Accuracy of the network on the 100 tran images: 81.000 %\n",
            "epoch 7 cost 39.060860 sec\n",
            "[8,   499] loss: 0.4165\n",
            "Accuracy of the network on the 100 tran images: 84.000 %\n",
            "epoch 8 cost 38.942786 sec\n",
            "[9,   499] loss: 0.3752\n",
            "Accuracy of the network on the 100 tran images: 88.000 %\n",
            "epoch 9 cost 39.005955 sec\n",
            "[10,   499] loss: 0.3534\n",
            "Accuracy of the network on the 100 tran images: 87.000 %\n",
            "epoch 10 cost 39.077304 sec\n",
            "[11,   499] loss: 0.3271\n",
            "Accuracy of the network on the 100 tran images: 90.000 %\n",
            "epoch 11 cost 39.168642 sec\n",
            "[12,   499] loss: 0.3008\n",
            "Accuracy of the network on the 100 tran images: 93.000 %\n",
            "epoch 12 cost 39.046951 sec\n",
            "[13,   499] loss: 0.2776\n",
            "Accuracy of the network on the 100 tran images: 92.000 %\n",
            "epoch 13 cost 39.095125 sec\n",
            "[14,   499] loss: 0.2591\n",
            "Accuracy of the network on the 100 tran images: 89.000 %\n",
            "epoch 14 cost 39.241067 sec\n",
            "[15,   499] loss: 0.2482\n",
            "Accuracy of the network on the 100 tran images: 91.000 %\n",
            "epoch 15 cost 39.139687 sec\n",
            "[16,   499] loss: 0.2260\n",
            "Accuracy of the network on the 100 tran images: 93.000 %\n",
            "epoch 16 cost 39.108727 sec\n",
            "[17,   499] loss: 0.2119\n",
            "Accuracy of the network on the 100 tran images: 94.000 %\n",
            "epoch 17 cost 39.119967 sec\n",
            "[18,   499] loss: 0.2026\n",
            "Accuracy of the network on the 100 tran images: 95.000 %\n",
            "epoch 18 cost 39.135493 sec\n",
            "[19,   499] loss: 0.1857\n",
            "Accuracy of the network on the 100 tran images: 92.000 %\n",
            "epoch 19 cost 39.155976 sec\n",
            "[20,   499] loss: 0.1787\n",
            "Accuracy of the network on the 100 tran images: 95.000 %\n",
            "epoch 20 cost 39.157528 sec\n",
            "[21,   499] loss: 0.1669\n",
            "Accuracy of the network on the 100 tran images: 93.000 %\n",
            "epoch 21 cost 39.165323 sec\n",
            "[22,   499] loss: 0.1599\n",
            "Accuracy of the network on the 100 tran images: 93.000 %\n",
            "epoch 22 cost 39.106738 sec\n",
            "[23,   499] loss: 0.1504\n",
            "Accuracy of the network on the 100 tran images: 98.000 %\n",
            "epoch 23 cost 39.071946 sec\n",
            "[24,   499] loss: 0.1461\n",
            "Accuracy of the network on the 100 tran images: 93.000 %\n",
            "epoch 24 cost 39.062921 sec\n",
            "[25,   499] loss: 0.1402\n",
            "Accuracy of the network on the 100 tran images: 93.000 %\n",
            "epoch 25 cost 39.186197 sec\n",
            "[26,   499] loss: 0.1289\n",
            "Accuracy of the network on the 100 tran images: 95.000 %\n",
            "epoch 26 cost 39.163433 sec\n",
            "[27,   499] loss: 0.1273\n",
            "Accuracy of the network on the 100 tran images: 96.000 %\n",
            "epoch 27 cost 39.167890 sec\n",
            "[28,   499] loss: 0.1213\n",
            "Accuracy of the network on the 100 tran images: 97.000 %\n",
            "epoch 28 cost 39.261265 sec\n",
            "[29,   499] loss: 0.1121\n",
            "Accuracy of the network on the 100 tran images: 96.000 %\n",
            "epoch 29 cost 39.364547 sec\n",
            "[30,   499] loss: 0.1140\n",
            "Accuracy of the network on the 100 tran images: 98.000 %\n",
            "epoch 30 cost 39.149682 sec\n",
            "[31,   499] loss: 0.1099\n",
            "Accuracy of the network on the 100 tran images: 95.000 %\n",
            "epoch 31 cost 38.955549 sec\n",
            "[32,   499] loss: 0.1021\n",
            "Accuracy of the network on the 100 tran images: 95.000 %\n",
            "epoch 32 cost 39.345654 sec\n",
            "[33,   499] loss: 0.1004\n",
            "Accuracy of the network on the 100 tran images: 95.000 %\n",
            "epoch 33 cost 39.367866 sec\n",
            "[34,   499] loss: 0.0961\n",
            "Accuracy of the network on the 100 tran images: 99.000 %\n",
            "epoch 34 cost 39.467799 sec\n",
            "[35,   499] loss: 0.0995\n",
            "Accuracy of the network on the 100 tran images: 98.000 %\n",
            "epoch 35 cost 39.305003 sec\n",
            "[36,   499] loss: 0.0970\n",
            "Accuracy of the network on the 100 tran images: 98.000 %\n",
            "epoch 36 cost 39.563938 sec\n",
            "[37,   499] loss: 0.0876\n",
            "Accuracy of the network on the 100 tran images: 95.000 %\n",
            "epoch 37 cost 39.531718 sec\n",
            "[38,   499] loss: 0.0882\n",
            "Accuracy of the network on the 100 tran images: 96.000 %\n",
            "epoch 38 cost 39.579317 sec\n",
            "[39,   499] loss: 0.0872\n",
            "Accuracy of the network on the 100 tran images: 93.000 %\n",
            "epoch 39 cost 39.378935 sec\n",
            "[40,   499] loss: 0.0875\n",
            "Accuracy of the network on the 100 tran images: 100.000 %\n",
            "epoch 40 cost 40.067168 sec\n",
            "[41,   499] loss: 0.0792\n",
            "Accuracy of the network on the 100 tran images: 97.000 %\n",
            "epoch 41 cost 39.501707 sec\n",
            "[42,   499] loss: 0.0805\n",
            "Accuracy of the network on the 100 tran images: 98.000 %\n",
            "epoch 42 cost 39.653198 sec\n",
            "[43,   499] loss: 0.0780\n",
            "Accuracy of the network on the 100 tran images: 98.000 %\n",
            "epoch 43 cost 39.548530 sec\n",
            "[44,   499] loss: 0.0743\n",
            "Accuracy of the network on the 100 tran images: 99.000 %\n",
            "epoch 44 cost 39.553683 sec\n",
            "[45,   499] loss: 0.0763\n",
            "Accuracy of the network on the 100 tran images: 98.000 %\n",
            "epoch 45 cost 39.644687 sec\n",
            "[46,   499] loss: 0.0741\n",
            "Accuracy of the network on the 100 tran images: 96.000 %\n",
            "epoch 46 cost 39.540292 sec\n",
            "[47,   499] loss: 0.0735\n",
            "Accuracy of the network on the 100 tran images: 98.000 %\n",
            "epoch 47 cost 39.601708 sec\n",
            "[48,   499] loss: 0.0705\n",
            "Accuracy of the network on the 100 tran images: 100.000 %\n",
            "epoch 48 cost 39.681911 sec\n",
            "[49,   499] loss: 0.0748\n",
            "Accuracy of the network on the 100 tran images: 98.000 %\n",
            "epoch 49 cost 39.631152 sec\n",
            "[50,   499] loss: 0.0683\n",
            "Accuracy of the network on the 100 tran images: 98.000 %\n",
            "epoch 50 cost 39.816518 sec\n",
            "[51,   499] loss: 0.0666\n",
            "Accuracy of the network on the 100 tran images: 99.000 %\n",
            "epoch 51 cost 39.759402 sec\n",
            "[52,   499] loss: 0.0642\n",
            "Accuracy of the network on the 100 tran images: 97.000 %\n",
            "epoch 52 cost 39.591680 sec\n",
            "[53,   499] loss: 0.0680\n",
            "Accuracy of the network on the 100 tran images: 99.000 %\n",
            "epoch 53 cost 39.664201 sec\n",
            "[54,   499] loss: 0.0655\n",
            "Accuracy of the network on the 100 tran images: 97.000 %\n",
            "epoch 54 cost 39.602895 sec\n",
            "[55,   499] loss: 0.0620\n",
            "Accuracy of the network on the 100 tran images: 98.000 %\n",
            "epoch 55 cost 39.748440 sec\n",
            "[56,   499] loss: 0.0631\n",
            "Accuracy of the network on the 100 tran images: 97.000 %\n",
            "epoch 56 cost 39.914881 sec\n",
            "[57,   499] loss: 0.0622\n",
            "Accuracy of the network on the 100 tran images: 99.000 %\n",
            "epoch 57 cost 39.800052 sec\n",
            "[58,   499] loss: 0.0589\n",
            "Accuracy of the network on the 100 tran images: 96.000 %\n",
            "epoch 58 cost 39.651121 sec\n",
            "[59,   499] loss: 0.0563\n",
            "Accuracy of the network on the 100 tran images: 99.000 %\n",
            "epoch 59 cost 39.588702 sec\n",
            "[60,   499] loss: 0.0580\n",
            "Accuracy of the network on the 100 tran images: 99.000 %\n",
            "epoch 60 cost 39.553922 sec\n",
            "[61,   499] loss: 0.0563\n",
            "Accuracy of the network on the 100 tran images: 98.000 %\n",
            "epoch 61 cost 39.602562 sec\n",
            "[62,   499] loss: 0.0565\n",
            "Accuracy of the network on the 100 tran images: 96.000 %\n",
            "epoch 62 cost 39.619816 sec\n",
            "[63,   499] loss: 0.0555\n",
            "Accuracy of the network on the 100 tran images: 96.000 %\n",
            "epoch 63 cost 39.507674 sec\n",
            "[64,   499] loss: 0.0555\n",
            "Accuracy of the network on the 100 tran images: 97.000 %\n",
            "epoch 64 cost 39.569032 sec\n",
            "[65,   499] loss: 0.0544\n",
            "Accuracy of the network on the 100 tran images: 98.000 %\n",
            "epoch 65 cost 39.465748 sec\n",
            "[66,   499] loss: 0.0531\n",
            "Accuracy of the network on the 100 tran images: 99.000 %\n",
            "epoch 66 cost 39.560421 sec\n",
            "[67,   499] loss: 0.0541\n",
            "Accuracy of the network on the 100 tran images: 98.000 %\n",
            "epoch 67 cost 39.652740 sec\n",
            "[68,   499] loss: 0.0539\n",
            "Accuracy of the network on the 100 tran images: 98.000 %\n",
            "epoch 68 cost 39.956338 sec\n",
            "[69,   499] loss: 0.0543\n",
            "Accuracy of the network on the 100 tran images: 99.000 %\n",
            "epoch 69 cost 39.606057 sec\n",
            "[70,   499] loss: 0.0507\n",
            "Accuracy of the network on the 100 tran images: 98.000 %\n",
            "epoch 70 cost 39.539052 sec\n",
            "[71,   499] loss: 0.0506\n",
            "Accuracy of the network on the 100 tran images: 97.000 %\n",
            "epoch 71 cost 39.571478 sec\n",
            "[72,   499] loss: 0.0485\n",
            "Accuracy of the network on the 100 tran images: 99.000 %\n",
            "epoch 72 cost 39.575804 sec\n",
            "[73,   499] loss: 0.0490\n",
            "Accuracy of the network on the 100 tran images: 100.000 %\n",
            "epoch 73 cost 39.466985 sec\n",
            "[74,   499] loss: 0.0486\n",
            "Accuracy of the network on the 100 tran images: 99.000 %\n",
            "epoch 74 cost 39.661872 sec\n",
            "[75,   499] loss: 0.0508\n",
            "Accuracy of the network on the 100 tran images: 97.000 %\n",
            "epoch 75 cost 39.419816 sec\n",
            "[76,   499] loss: 0.0457\n",
            "Accuracy of the network on the 100 tran images: 98.000 %\n",
            "epoch 76 cost 39.449596 sec\n",
            "[77,   499] loss: 0.0465\n",
            "Accuracy of the network on the 100 tran images: 98.000 %\n",
            "epoch 77 cost 39.517088 sec\n",
            "[78,   499] loss: 0.0464\n",
            "Accuracy of the network on the 100 tran images: 98.000 %\n",
            "epoch 78 cost 39.336243 sec\n",
            "[79,   499] loss: 0.0453\n",
            "Accuracy of the network on the 100 tran images: 100.000 %\n",
            "epoch 79 cost 39.399657 sec\n",
            "[80,   499] loss: 0.0453\n",
            "Accuracy of the network on the 100 tran images: 99.000 %\n",
            "epoch 80 cost 39.529453 sec\n",
            "[81,   499] loss: 0.0449\n",
            "Accuracy of the network on the 100 tran images: 100.000 %\n",
            "epoch 81 cost 39.410066 sec\n",
            "[82,   499] loss: 0.0468\n",
            "Accuracy of the network on the 100 tran images: 98.000 %\n",
            "epoch 82 cost 39.381039 sec\n",
            "[83,   499] loss: 0.0465\n",
            "Accuracy of the network on the 100 tran images: 100.000 %\n",
            "epoch 83 cost 39.443020 sec\n",
            "[84,   499] loss: 0.0453\n",
            "Accuracy of the network on the 100 tran images: 100.000 %\n",
            "epoch 84 cost 39.434794 sec\n",
            "[85,   499] loss: 0.0410\n",
            "Accuracy of the network on the 100 tran images: 100.000 %\n",
            "epoch 85 cost 39.405386 sec\n",
            "[86,   499] loss: 0.0413\n",
            "Accuracy of the network on the 100 tran images: 100.000 %\n",
            "epoch 86 cost 39.258100 sec\n",
            "[87,   499] loss: 0.0439\n",
            "Accuracy of the network on the 100 tran images: 99.000 %\n",
            "epoch 87 cost 39.273131 sec\n",
            "[88,   499] loss: 0.0431\n",
            "Accuracy of the network on the 100 tran images: 99.000 %\n",
            "epoch 88 cost 39.319346 sec\n",
            "[89,   499] loss: 0.0421\n",
            "Accuracy of the network on the 100 tran images: 100.000 %\n",
            "epoch 89 cost 39.363193 sec\n",
            "[90,   499] loss: 0.0408\n",
            "Accuracy of the network on the 100 tran images: 98.000 %\n",
            "epoch 90 cost 39.329362 sec\n",
            "[91,   499] loss: 0.0410\n",
            "Accuracy of the network on the 100 tran images: 100.000 %\n",
            "epoch 91 cost 39.344658 sec\n",
            "[92,   499] loss: 0.0397\n",
            "Accuracy of the network on the 100 tran images: 99.000 %\n",
            "epoch 92 cost 39.323505 sec\n",
            "[93,   499] loss: 0.0406\n",
            "Accuracy of the network on the 100 tran images: 99.000 %\n",
            "epoch 93 cost 39.211845 sec\n",
            "[94,   499] loss: 0.0414\n",
            "Accuracy of the network on the 100 tran images: 99.000 %\n",
            "epoch 94 cost 39.179365 sec\n",
            "[95,   499] loss: 0.0425\n",
            "Accuracy of the network on the 100 tran images: 99.000 %\n",
            "epoch 95 cost 39.399708 sec\n",
            "[96,   499] loss: 0.0382\n",
            "Accuracy of the network on the 100 tran images: 97.000 %\n",
            "epoch 96 cost 39.297751 sec\n",
            "[97,   499] loss: 0.0390\n",
            "Accuracy of the network on the 100 tran images: 98.000 %\n",
            "epoch 97 cost 39.381885 sec\n",
            "[98,   499] loss: 0.0378\n",
            "Accuracy of the network on the 100 tran images: 99.000 %\n",
            "epoch 98 cost 39.240338 sec\n",
            "[99,   499] loss: 0.0380\n",
            "Accuracy of the network on the 100 tran images: 100.000 %\n",
            "epoch 99 cost 39.316081 sec\n",
            "Finished Training\n",
            "Accuracy of the network on the 10000 test images: 84.330 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "197SJRWJK4S5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "outputId": "e5e3444a-d3c8-4ce9-a6ae-0f340e56a22c"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcdefaults()\n",
        "from matplotlib.lines import Line2D\n",
        "from matplotlib.patches import Rectangle\n",
        "from matplotlib.patches import Circle\n",
        "\n",
        "NumDots = 4\n",
        "NumConvMax = 8\n",
        "NumFcMax = 20\n",
        "White = 1.\n",
        "Light = 0.7\n",
        "Medium = 0.5\n",
        "Dark = 0.3\n",
        "Darker = 0.15\n",
        "Black = 0.\n",
        "\n",
        "\n",
        "def add_layer(patches, colors, size=(5, 5), num=5,\n",
        "              top_left=[0, 0],\n",
        "              loc_diff=[3, -3],\n",
        "              ):\n",
        "    # add a rectangle\n",
        "    top_left = np.array(top_left)\n",
        "    loc_diff = np.array(loc_diff)\n",
        "    loc_start = top_left - np.array([0, size[0]])\n",
        "    for ind in range(num):\n",
        "        patches.append(Rectangle(loc_start + ind * loc_diff, size[1], size[0]))\n",
        "        if ind % 2:\n",
        "            colors.append(Medium)\n",
        "        else:\n",
        "            colors.append(Light)\n",
        "\n",
        "\n",
        "def add_layer_with_omission(patches, colors, size=(50, 50),\n",
        "                            num=5, num_max=8,\n",
        "                            num_dots=4,\n",
        "                            top_left=[0, 0],\n",
        "                            loc_diff=[3, -3],\n",
        "                            ):\n",
        "    # add a rectangle\n",
        "    top_left = np.array(top_left)\n",
        "    loc_diff = np.array(loc_diff)\n",
        "    loc_start = top_left - np.array([0, size[0]])\n",
        "    this_num = min(num, num_max)\n",
        "    start_omit = (this_num - num_dots) // 2\n",
        "    end_omit = this_num - start_omit\n",
        "    start_omit -= 1\n",
        "    for ind in range(this_num):\n",
        "        if (num > num_max) and (start_omit < ind < end_omit):\n",
        "            omit = True\n",
        "        else:\n",
        "            omit = False\n",
        "\n",
        "        if omit:\n",
        "            patches.append(\n",
        "                Circle(loc_start + ind * loc_diff + np.array(size) / 2, 0.5))\n",
        "        else:\n",
        "            patches.append(Rectangle(loc_start + ind * loc_diff,\n",
        "                                     size[1], size[0]))\n",
        "\n",
        "        if omit:\n",
        "            colors.append(Black)\n",
        "        elif ind % 2:\n",
        "            colors.append(Medium)\n",
        "        else:\n",
        "            colors.append(Light)\n",
        "\n",
        "\n",
        "def add_mapping(patches, colors, start_ratio, end_ratio, patch_size, ind_bgn,\n",
        "                top_left_list, loc_diff_list, num_show_list, size_list):\n",
        "\n",
        "    start_loc = top_left_list[ind_bgn] \\\n",
        "        + (num_show_list[ind_bgn] - 1) * np.array(loc_diff_list[ind_bgn]) \\\n",
        "        + np.array([start_ratio[0] * (size_list[ind_bgn][1] - patch_size[1]),\n",
        "                    - start_ratio[1] * (size_list[ind_bgn][0] - patch_size[0])]\n",
        "                   )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    end_loc = top_left_list[ind_bgn + 1] \\\n",
        "        + (num_show_list[ind_bgn + 1] - 1) * np.array(\n",
        "            loc_diff_list[ind_bgn + 1]) \\\n",
        "        + np.array([end_ratio[0] * size_list[ind_bgn + 1][1],\n",
        "                    - end_ratio[1] * size_list[ind_bgn + 1][0]])\n",
        "\n",
        "\n",
        "    patches.append(Rectangle(start_loc, patch_size[1], -patch_size[0]))\n",
        "    colors.append(Dark)\n",
        "    patches.append(Line2D([start_loc[0], end_loc[0]],\n",
        "                          [start_loc[1], end_loc[1]]))\n",
        "    colors.append(Darker)\n",
        "    patches.append(Line2D([start_loc[0] + patch_size[1], end_loc[0]],\n",
        "                          [start_loc[1], end_loc[1]]))\n",
        "    colors.append(Darker)\n",
        "    patches.append(Line2D([start_loc[0], end_loc[0]],\n",
        "                          [start_loc[1] - patch_size[0], end_loc[1]]))\n",
        "    colors.append(Darker)\n",
        "    patches.append(Line2D([start_loc[0] + patch_size[1], end_loc[0]],\n",
        "                          [start_loc[1] - patch_size[0], end_loc[1]]))\n",
        "    colors.append(Darker)\n",
        "\n",
        "\n",
        "\n",
        "def label(xy, text, xy_off=[0, 4]):\n",
        "    plt.text(xy[0] + xy_off[0], xy[1] + xy_off[1], text,\n",
        "             family='sans-serif', size=7)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    fc_unit_size = 3\n",
        "    layer_width = 20\n",
        "    flag_omit = False\n",
        "\n",
        "    patches = []\n",
        "    colors = []\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "\n",
        "\n",
        "    ############################\n",
        "    # conv layers input      conv1     conv2     pool1     conv3     conv4    pool2   conv5   conv6   conv7     pool3   conv8   conv9   conv10  pool4                  conv13   pool5\n",
        "    size_list = [(32, 32), (32, 32), (32, 32), (16, 16), (16, 16), (16, 16), (9, 9), (9, 9), (9, 9), (11 ,11), (6, 6), (6, 6), (6, 6), (8, 8), (5, 5), (5, 5), (5, 5), (7, 7), (4, 4)]\n",
        "    num_list = [3, 64, 64, 64, 128, 128, 128, 128, 128, 128, 128, 256, 256, 256, 256, 512, 512, 512, 512]\n",
        "    x_diff_list = [0, layer_width + 30, layer_width + 30, layer_width + 30, layer_width + 30, layer_width + 30, layer_width + 30, layer_width + 30, layer_width + 30, layer_width + 30, layer_width + 30, layer_width + 30, layer_width + 30, layer_width + 30, layer_width + 30, layer_width + 30, layer_width + 30, layer_width + 30, layer_width + 30]\n",
        "    text_list = ['Inputs'] + ['Feature\\nmaps'] * (len(size_list) - 1)\n",
        "    loc_diff_list = [[3, -3]] * len(size_list)\n",
        "\n",
        "    num_show_list = list(map(min, num_list, [NumConvMax] * len(num_list)))\n",
        "    top_left_list = np.c_[np.cumsum(x_diff_list), np.zeros(len(x_diff_list))]\n",
        "\n",
        "    for ind in range(len(size_list)-1,-1,-1):\n",
        "        if flag_omit:\n",
        "            add_layer_with_omission(patches, colors, size=size_list[ind],\n",
        "                                    num=num_list[ind],\n",
        "                                    num_max=NumConvMax,\n",
        "                                    num_dots=NumDots,\n",
        "                                    top_left=top_left_list[ind],\n",
        "                                    loc_diff=loc_diff_list[ind])\n",
        "        else:\n",
        "            add_layer(patches, colors, size=size_list[ind],\n",
        "                      num=num_show_list[ind],\n",
        "                      top_left=top_left_list[ind], loc_diff=loc_diff_list[ind])\n",
        "        label(top_left_list[ind], text_list[ind] + '\\n{}@{}x{}'.format(\n",
        "            num_list[ind], size_list[ind][0], size_list[ind][1]))\n",
        "\n",
        "    ############################\n",
        "    # in between layers\n",
        "    start_ratio_list = [[0.4, 0.5], [0.4, 0.5], [0.4, 0.8], [0.4, 0.5], [0.4, 0.5], [0.4, 0.8], [0.4, 0.5], [0.4, 0.5], [0.4, 0.5], [0.4, 0.8], [0.4, 0.5], [0.4, 0.5], [0.4, 0.5], [0.4, 0.8], [0.4, 0.5], [0.4, 0.5], [0.4, 0.5], [0.4, 0.8]]\n",
        "    end_ratio_list = [[0.4, 0.5], [0.4, 0.5], [0.4, 0.8], [0.4, 0.5], [0.4, 0.5], [0.4, 0.8], [0.4, 0.5], [0.4, 0.5], [0.4, 0.5], [0.4, 0.8], [0.4, 0.5], [0.4, 0.5], [0.4, 0.5], [0.4, 0.8], [0.4, 0.5], [0.4, 0.5], [0.4, 0.5], [0.4, 0.8]]\n",
        "    patch_size_list = [(3, 3), (3, 3), (2, 2), (3, 3), (3, 3), (2, 2), (3, 3)]\n",
        "    ind_bgn_list = range(len(patch_size_list))\n",
        "    text_list = ['Convolution', 'Convolution', 'Max-pooling', 'Convolution', 'Convolution', 'Max-pooling', 'Convolution', 'Convolution' 'Convolution', 'Max-pooling', 'Convolution', 'Convolution' 'Convolution', 'Max-pooling', 'Convolution', 'Convolution' 'Convolution', 'Max-pooling']\n",
        "\n",
        "    for ind in range(len(patch_size_list)):\n",
        "        add_mapping(\n",
        "            patches, colors, start_ratio_list[ind], end_ratio_list[ind],\n",
        "            patch_size_list[ind], ind,\n",
        "            top_left_list, loc_diff_list, num_show_list, size_list)\n",
        "        label(top_left_list[ind], text_list[ind] + '\\n{}x{} kernel'.format(\n",
        "            patch_size_list[ind][0], patch_size_list[ind][1]), xy_off=[26, -65]\n",
        "        )\n",
        "\n",
        "\n",
        "    ############################\n",
        "    # fully connected layers\n",
        "    size_list = [(fc_unit_size, fc_unit_size)] * 3\n",
        "    num_list = [512*4*4, 1024, 1024, 10]\n",
        "    num_show_list = list(map(min, num_list, [NumFcMax] * len(num_list)))\n",
        "    x_diff_list = [sum(x_diff_list) + layer_width, layer_width, layer_width]\n",
        "    top_left_list = np.c_[np.cumsum(x_diff_list), np.zeros(len(x_diff_list))]\n",
        "    loc_diff_list = [[fc_unit_size, -fc_unit_size]] * len(top_left_list)\n",
        "    text_list = ['Hidden\\nunits'] * (len(size_list) - 1) + ['Outputs']\n",
        "\n",
        "    for ind in range(len(size_list)):\n",
        "        if flag_omit:\n",
        "            add_layer_with_omission(patches, colors, size=size_list[ind],\n",
        "                                    num=num_list[ind],\n",
        "                                    num_max=NumFcMax,\n",
        "                                    num_dots=NumDots,\n",
        "                                    top_left=top_left_list[ind],\n",
        "                                    loc_diff=loc_diff_list[ind])\n",
        "        else:\n",
        "            add_layer(patches, colors, size=size_list[ind],\n",
        "                      num=num_show_list[ind],\n",
        "                      top_left=top_left_list[ind],\n",
        "                      loc_diff=loc_diff_list[ind])\n",
        "        label(top_left_list[ind], text_list[ind] + '\\n{}'.format(\n",
        "            num_list[ind]))\n",
        "\n",
        "    text_list = ['Flatten\\n', 'Fully\\nconnected', 'Fully\\nconnected']\n",
        "\n",
        "    for ind in range(len(size_list)):\n",
        "        label(top_left_list[ind], text_list[ind], xy_off=[-10, -65])\n",
        "\n",
        "    ############################\n",
        "    for patch, color in zip(patches, colors):\n",
        "        patch.set_color(color * np.ones(3))\n",
        "        if isinstance(patch, Line2D):\n",
        "            ax.add_line(patch)\n",
        "        else:\n",
        "            patch.set_edgecolor(Black * np.ones(3))\n",
        "            ax.add_patch(patch)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.axis('equal')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "    fig.set_size_inches(8, 2.5)\n",
        "\n",
        "    fig_dir = './'\n",
        "    fig_ext = '.png'\n",
        "    fig.savefig(os.path.join(fig_dir, 'convnet_fig' + fig_ext),\n",
        "                bbox_inches='tight', pad_inches=0)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/matplotlib/tight_layout.py:176: UserWarning: Tight layout not applied. The left and right margins cannot be made large enough to accommodate all axes decorations. \n",
            "  warnings.warn('Tight layout not applied. The left and right margins '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjMAAAGdCAYAAADnrPLBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ng1tl0SBLBSS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}